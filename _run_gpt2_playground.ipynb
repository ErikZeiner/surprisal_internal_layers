{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T21:32:36.033043Z",
     "start_time": "2025-08-12T21:32:30.719133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tuned_lens import TunedLens\n",
    "from _config import HUFFINGFACE_KEY\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "##NNSIGHT\n",
    "\n",
    "import nnsight\n",
    "from nnsight import NNsight, LanguageModel\n",
    "\n",
    "\n",
    "##TRANSFORMER-LENS\n",
    "\n",
    "# import transformer_lens.utils as utils\n",
    "# from transformer_lens.hook_points import (\n",
    "#     HookPoint,\n",
    "# )  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# parser = argparse.ArgumentParser()\n",
    "model_name = 'gpt2'\n",
    "batchsize = 4\n",
    "quantize = ''\n",
    "data = 'DC'\n",
    "trial = True\n",
    "method = 'logit-lens'\n",
    "cache = os.path.expanduser('./tmp/cashe/')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "article2tokens = json.load(open(f\"data/{data}/tokens.json\"))\n",
    "loss_fct = CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n",
    "\n",
    "access_token = HUFFINGFACE_KEY\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "path = f\"results/{method}/{data}/{os.path.basename(model_name)}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "if quantize == \"4bit\":\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token, load_in_4bit=True,cache_dir=cache)\n",
    "    hf_model.eval()\n",
    "elif quantize == \"8bit\":\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token, load_in_8bit=True,cache_dir=cache)\n",
    "    hf_model.eval()\n",
    "else:\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token, cache_dir=cache)\n",
    "    hf_model.to(device).eval()\n",
    "\n",
    "if \"gpt\" in model_name or \"falcon\" in model_name:\n",
    "    last_ln = hf_model.transformer.ln_f\n",
    "    lm_head = hf_model.lm_head\n",
    "elif \"opt\" in model_name:\n",
    "    last_ln = hf_model.model.decoder.final_layer_norm  # changed\n",
    "    lm_head = hf_model.lm_head\n",
    "elif \"xglm\" in model_name:\n",
    "    last_ln = hf_model.model.layer_norm\n",
    "    lm_head = hf_model.lm_head\n",
    "elif \"pythia\" in model_name:\n",
    "    last_ln = hf_model.gpt_neox.final_layer_norm\n",
    "    lm_head = hf_model.embed_out\n",
    "else:\n",
    "    raise ValueError(\"model name must contain 'gpt,' 'opt,' or 'falcon'\")\n",
    "\n",
    "loss_fct = CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n",
    "bos_string = tokenizer.decode(hf_model.config.bos_token_id)\n",
    "article2surprisals = defaultdict(lambda: defaultdict(list))\n",
    "# article2entropies = defaultdict(lambda: defaultdict(list))\n",
    "# article2renyi_entropies = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "if trial:\n",
    "    article2tokens = {k: v for k, v in list(article2tokens.items())[:1]}\n",
    "\n",
    "eps = 1e-8\n",
    "if method == \"tuned-lens\":\n",
    "    tuned_lens = TunedLens.from_model_and_pretrained(hf_model).to(hf_model.device)"
   ],
   "id": "8d2ca3fa1a62ccd7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikzeiner/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:37:36.856689Z",
     "start_time": "2025-08-12T14:37:36.842817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Define helper functions\n",
    "\n",
    "def def_trans_lens_model(model_name):\n",
    "    return HookedTransformer.from_pretrained(model_name, device=device).to(device)\n",
    "\n",
    "def def_nnsight_wrap(model):\n",
    "    nn_model = NNsight(model)\n",
    "    layers = nn_model.transformer.h\n",
    "    return nn_model,layers\n",
    "\n",
    "def get_nn_logits(model, layers, sents):\n",
    "    '''Get output from all layers in nnsight'''\n",
    "    nn_outputs = []\n",
    "    with model.trace() as tracer:\n",
    "        with tracer.invoke(sents) as invoker:\n",
    "            # hidden layers: token embeddings + 12 transformer outputs\n",
    "\n",
    "            # get token embedding\n",
    "            token_embd = model.transformer.wte.output + model.transformer.wpe.output\n",
    "            nn_outputs.append(model.lm_head(token_embd).save())\n",
    "            # get transformer block embeddings\n",
    "            for layer_id, layer in enumerate(layers):\n",
    "                if layer_id == len(layers) - 1:\n",
    "                    nn_outputs.append(model.lm_head(model.transformer.ln_f(layer.output[0])).save())\n",
    "                else:\n",
    "                    nn_outputs.append(model.lm_head(layer.output[0]).save())\n",
    "    return torch.stack(nn_outputs).to(device)\n",
    "\n",
    "def get_base_logits(model, sents):\n",
    "    output = hf_model(sents, output_hidden_states=True)\n",
    "    return lm_head(torch.stack(output[2]).to(device))\n",
    "\n",
    "def get_trans_lens_logits(model, sents):\n",
    "    # tokens = model.to_tokens(prompt, prepend_bos=False)\n",
    "    logits, cache = model.run_with_cache(sents, remove_batch_dim=False)\n",
    "    embed = model.embed(sents) + model.pos_embed(sents)\n",
    "    # if model.cfg.final_rms:\n",
    "    #     embed = model.ln_final(embed)\n",
    "\n",
    "    layer_logits = [model.unembed(embed)]\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        resid = cache[\"resid_post\", layer]\n",
    "        if layer == model.cfg.n_layers - 1 and model.cfg.final_rms:\n",
    "            resid = model.ln_final(resid)\n",
    "        # layer_logits.append(model.unembed(resid))\n",
    "\n",
    "        logits_at_layer = model.unembed(resid)\n",
    "        layer_logits.append(logits_at_layer)\n",
    "    return torch.stack(layer_logits).to(device)\n",
    "\n",
    "def layer_by_layer_comp(logits1, logits2):\n",
    "    # assert logits1.shape != logits2.shape\n",
    "    table = PrettyTable()\n",
    "    table.align = 'l'\n",
    "    table.field_names = [\"layer\", \"allclose\"]\n",
    "    for i in range(len(logits1)):\n",
    "        table.add_row([i,torch.allclose(logits1[i], logits2[i])])\n",
    "    print(table)\n",
    "\n",
    "def get_predicted(logit):\n",
    "    return tokenizer.decode(torch.argmax(logit, dim=-1)[0][-1])"
   ],
   "id": "b30090f1a5311f0c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-12T14:37:56.673348Z",
     "start_time": "2025-08-12T14:37:54.211888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt = \"The London Bridge is in the city of\"\n",
    "prompt = \"The Eiffel Tower is in the city of\"\n",
    "\n",
    "encoded_sents = tokenizer(prompt, return_tensors=\"pt\", padding=True, add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "## nnsight\n",
    "\n",
    "nn_model, layers1 = def_nnsight_wrap(hf_model)\n",
    "tl_model = def_trans_lens_model(model_name)\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:26:30.440312Z",
     "start_time": "2025-07-08T13:26:30.252858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lm_head(reps[-1]) is just the same as base_outputs.logits\n",
    "# layer_logit = lm_head(reps[-1])\n",
    "#\n",
    "# print(layer_logit.shape, base_outputs.logits.shape)\n",
    "# print(torch.allclose(layer_logit, base_outputs.logits))"
   ],
   "id": "c876d2737b151982",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 50257]) torch.Size([1, 10, 50257])\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T17:05:40.097174Z",
     "start_time": "2025-08-08T17:05:38.067345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comparing plain vs encoded as input to the tracer + comparison to base\n",
    "comp_model = LanguageModel(model_name, device_map=\"auto\")\n",
    "\n",
    "with comp_model.trace(prompt):\n",
    "    output_un = comp_model.output.save()\n",
    "\n",
    "with comp_model.trace(encoded_sents):\n",
    "    output_en = comp_model.output.save()\n",
    "\n",
    "print(torch.allclose(output_un.logits, output_en.logits))\n",
    "# print(torch.allclose(output_un.logits.to(device), base_outputs.logits.to(device)))\n",
    "# print(base_outputs.logits.shape, output_un.logits.shape)\n",
    "\n",
    "# This used to have a strange effect, now its here just as a check\n",
    "\n",
    "with comp_model.trace(bos_string + \" The London Bridge is in the city of\"):\n",
    "    output_bos = comp_model.lm_head.output.save()\n",
    "\n",
    "with comp_model.trace(\"The London Bridge is in the city of\"):\n",
    "    output_nobos = comp_model.lm_head.output.save()\n",
    "\n",
    "print(comp_model.tokenizer.decode(torch.argmax(output_bos, dim=-1)[0][-1]),comp_model.tokenizer.decode(torch.argmax(output_nobos, dim=-1)[0][-1]))"
   ],
   "id": "b6ecbcfb29136448",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      " London  London\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T14:38:01.904820Z",
     "start_time": "2025-08-12T14:38:00.548886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get predicted word for base and nnsight\n",
    "nn_logits = get_nn_logits(nn_model,layers1,encoded_sents)[-1]\n",
    "base_logits = get_base_logits(hf_model, encoded_sents)[-1]\n",
    "\n",
    "nn_pred = tokenizer.decode(torch.argmax(nn_logits, dim=-1)[0][-1])\n",
    "base_pred = tokenizer.decode(torch.argmax(base_logits, dim=-1)[0][-1])\n",
    "\n",
    "print(nn_pred, base_pred)\n",
    "print(torch.allclose(nn_logits,base_logits))"
   ],
   "id": "12c89244097638d7",
   "outputs": [
    {
     "ename": "NNsightError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 10, 50257] at entry 0 and [1, 10, 768] at entry 1",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"/Users/erikzeiner/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/tracing/graph/node.py\", line 297, in execute",
      "    output = self.target(*args, **kwargs)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "RuntimeError: stack expects each tensor to be equal size, but got [1, 10, 50257] at entry 0 and [1, 10, 768] at entry 1",
      "",
      "NNsightError: stack expects each tensor to be equal size, but got [1, 10, 50257] at entry 0 and [1, 10, 768] at entry 1"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T12:25:01.276439Z",
     "start_time": "2025-08-11T12:25:00.953836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Per layer comparison of base and nnsight outputs\n",
    "\n",
    "nn_logits = get_nn_logits(nn_model,layers1,encoded_sents)\n",
    "base_logits = get_base_logits(hf_model, encoded_sents)\n",
    "\n",
    "layer_by_layer_comp(nn_logits,base_logits)"
   ],
   "id": "212276fa9e17d49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| layer | allclose |\n",
      "+-------+----------+\n",
      "| 0     | True     |\n",
      "| 1     | True     |\n",
      "| 2     | True     |\n",
      "| 3     | True     |\n",
      "| 4     | True     |\n",
      "| 5     | True     |\n",
      "| 6     | True     |\n",
      "| 7     | True     |\n",
      "| 8     | True     |\n",
      "| 9     | True     |\n",
      "| 10    | True     |\n",
      "| 11    | True     |\n",
      "| 12    | True     |\n",
      "+-------+----------+\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T12:25:11.779974Z",
     "start_time": "2025-08-11T12:25:11.451542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Per layer comparison of base and nnsight outputs\n",
    "# I had to apply ln_f inversly to what it is in the base for some reason\n",
    "nn_logits = get_nn_logits(nn_model,layers1,encoded_sents)\n",
    "base_logits = get_base_logits(hf_model, encoded_sents)\n",
    "\n",
    "layer_by_layer_comp(nn_logits,base_logits)"
   ],
   "id": "ab9012ac4cbef64a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| layer | allclose |\n",
      "+-------+----------+\n",
      "| 0     | True     |\n",
      "| 1     | True     |\n",
      "| 2     | True     |\n",
      "| 3     | True     |\n",
      "| 4     | True     |\n",
      "| 5     | True     |\n",
      "| 6     | True     |\n",
      "| 7     | True     |\n",
      "| 8     | True     |\n",
      "| 9     | True     |\n",
      "| 10    | True     |\n",
      "| 11    | True     |\n",
      "| 12    | True     |\n",
      "+-------+----------+\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T12:25:26.057380Z",
     "start_time": "2025-08-11T12:25:24.777186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tl_logits = get_trans_lens_logits(tl_model,encoded_sents)\n",
    "base_logits = get_base_logits(hf_model, encoded_sents)\n",
    "\n",
    "layer_by_layer_comp(tl_logits,base_logits)\n",
    "# tl_logits[-1].shape, base_logits[-1].shape\n",
    "# len(tl_logits),len(base_logits)"
   ],
   "id": "e8d796472243ea9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| layer | allclose |\n",
      "+-------+----------+\n",
      "| 0     | False    |\n",
      "| 1     | False    |\n",
      "| 2     | False    |\n",
      "| 3     | False    |\n",
      "| 4     | False    |\n",
      "| 5     | False    |\n",
      "| 6     | False    |\n",
      "| 7     | False    |\n",
      "| 8     | False    |\n",
      "| 9     | False    |\n",
      "| 10    | False    |\n",
      "| 11    | False    |\n",
      "| 12    | False    |\n",
      "+-------+----------+\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:24:21.113235Z",
     "start_time": "2025-07-17T04:24:21.108513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"HF embed weights [0,:5]:\", hf_model.transformer.wte.weight[0,:5])\n",
    "print(\"TL embed weights [0,:5]:\", tl_model.embed.W_E[0,:5])\n",
    "print(\"HF pos weights [0,:5]:\", hf_model.transformer.wpe.weight[0,:5])\n",
    "print(\"TL pos weights [0,:5]:\", tl_model.pos_embed.W_pos[0,:5])"
   ],
   "id": "25e1a9f2d3b65d91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF embed weights [0,:5]: tensor([-0.1101, -0.0393,  0.0331,  0.1338, -0.0485], grad_fn=<SliceBackward0>)\n",
      "TL embed weights [0,:5]: tensor([-0.1106, -0.0398,  0.0326,  0.1333, -0.0490], grad_fn=<SliceBackward0>)\n",
      "HF pos weights [0,:5]: tensor([-0.0188, -0.1974,  0.0040,  0.0113,  0.0638], grad_fn=<SliceBackward0>)\n",
      "TL pos weights [0,:5]: tensor([-0.0134, -0.1920,  0.0095,  0.0168,  0.0693], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T17:05:55.472679Z",
     "start_time": "2025-08-08T17:05:53.097628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tl_model = def_trans_lens_model(model_name)\n",
    "\n",
    "tl_model.generate(prompt, max_new_tokens=1,prepend_bos=True)"
   ],
   "id": "bca1dbca48f66313",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Eiffel Tower is in the city of Tokyo'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T17:06:02.277579Z",
     "start_time": "2025-08-08T17:05:58.517226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model1 = HookedTransformer.from_pretrained('gpt2', device=device)\n",
    "model2 = HookedTransformer.from_pretrained('gpt2-small', device=device)"
   ],
   "id": "150c9a564f7a274e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T17:06:05.594953Z",
     "start_time": "2025-08-08T17:06:05.369316Z"
    }
   },
   "cell_type": "code",
   "source": "model1.generate(prompt, max_new_tokens=1, temperature=0.7,prepend_bos=True)",
   "id": "3240e41a0777c74a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Eiffel Tower is in the city of Birmingham'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T17:06:08.696022Z",
     "start_time": "2025-08-08T17:06:08.501346Z"
    }
   },
   "cell_type": "code",
   "source": "model2.generate(prompt, max_new_tokens=1, temperature=0.7,prepend_bos=True)",
   "id": "8980fc892d5f1fc1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Eiffel Tower is in the city of Oslo'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T15:06:02.726457Z",
     "start_time": "2025-06-28T15:06:02.697597Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7762,  2634,   563, 50256, 50256],\n",
       "        [ 7762,   171,   120,   111,    88]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35,
   "source": [
    "# NOT RELEVANT - just some checks for the encoding issue§\n",
    "\n",
    "# encoded_sent = tokenizer(['Valéry', 'ValＳy'], return_tensors=\"pt\", padding=True,\n",
    "#                          add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "# print(encoded_sent)\n",
    "#\n",
    "# import unicodedata\n",
    "#\n",
    "# text = \"ValＳy\"\n",
    "# print(\"Before normalization:\", [hex(ord(c)) for c in text])\n",
    "# normalized = unicodedata.normalize(\"NFKC\", text)\n",
    "# print(\"After normalization:\", [hex(ord(c)) for c in normalized])"
   ],
   "id": "78720e80a915c081"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
