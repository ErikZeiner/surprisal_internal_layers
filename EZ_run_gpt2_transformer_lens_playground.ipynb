{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T15:16:27.968846Z",
     "start_time": "2025-07-13T15:16:23.882452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tuned_lens import TunedLens\n",
    "\n",
    "from _config import HUFFINGFACE_KEY\n",
    "\n",
    "\n",
    "# import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix"
   ],
   "id": "58cf885003c4197c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikzeiner/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:26:03.291265Z",
     "start_time": "2025-07-08T18:26:00.606841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = 'The London Bridge is in the city of'\n",
    "device = utils.get_device()\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
   ],
   "id": "681aeb31b11afddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:45:00.687859Z",
     "start_time": "2025-07-08T18:44:56.395966Z"
    }
   },
   "cell_type": "code",
   "source": "model.generate(prompt, max_new_tokens=1,temperature=0.7,prepend_bos=True)",
   "id": "9e41634801c11a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The London Bridge is in the city of London'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:34:57.902659Z",
     "start_time": "2025-07-08T18:34:57.818756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = model.to_tokens(prompt)\n",
    "logits, cache = model.run_with_cache(tokens, remove_batch_dim=True)\n",
    "print(model.cfg.n_layers)"
   ],
   "id": "ef8d5ac2623a0ffe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:34:59.930146Z",
     "start_time": "2025-07-08T18:34:59.921054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get token embeddings (input to the model)\n",
    "# Shape: [batch, seq_len, d_model]\n",
    "embed = model.embed(tokens) + model.pos_embed(tokens)\n",
    "# Apply layer norm if model uses final_rms (usually False at input, but check)\n",
    "if model.cfg.final_rms:\n",
    "    embed = model.ln_final(embed)\n",
    "\n",
    "# Get logits from input embeddings\n",
    "layer_logits = [model.unembed(embed)]\n",
    "\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    # Get residual stream at this point\n",
    "    resid = cache[\"resid_post\", layer]  # Shape: [batch, seq_len, d_model]\n",
    "\n",
    "    # Apply final LayerNorm if needed\n",
    "    if model.cfg.final_rms:\n",
    "        resid = model.ln_final(resid)\n",
    "\n",
    "    # Compute logits: [batch, seq_len, d_vocab]\n",
    "    logits_at_layer = model.unembed(resid)\n",
    "    layer_logits.append(logits_at_layer)"
   ],
   "id": "dcd88290a52b66f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:35:02.637953Z",
     "start_time": "2025-07-08T18:35:02.631583Z"
    }
   },
   "cell_type": "code",
   "source": "len(layer_logits)",
   "id": "885879d93eb9d0e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c01571b1d98775a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
