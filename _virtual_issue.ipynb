{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T03:12:04.339619Z",
     "start_time": "2025-07-17T03:12:04.308123Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from _config import HUFFINGFACE_KEY\n",
    "\n",
    "##NNSIGHT\n",
    "\n",
    "import nnsight\n",
    "from nnsight import NNsight, LanguageModel\n",
    "\n",
    "\n",
    "##TRANSFORMER-LENS\n",
    "\n",
    "# import transformer_lens.utils as utils\n",
    "# from transformer_lens.hook_points import (\n",
    "#     HookPoint,\n",
    "# )  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:12:06.903507Z",
     "start_time": "2025-07-17T03:12:06.893333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = 'The Eiffel Tower is in the city of'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "ca758845c05c950e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:12:11.573017Z",
     "start_time": "2025-07-17T03:12:08.826391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer-lens\n",
    "model_name = \"gpt2\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, force_download=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, force_download=True)\n",
    "model1 = HookedTransformer.from_pretrained('gpt2', device=device)\n"
   ],
   "id": "76100c6cde48d49d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:12:22.039908Z",
     "start_time": "2025-07-17T03:12:21.948493Z"
    }
   },
   "cell_type": "code",
   "source": "model1.generate(prompt, max_new_tokens=1,prepend_bos=True)",
   "id": "665c7cb4115bc1f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Eiffel Tower is in the city of Paris'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:12:28.351959Z",
     "start_time": "2025-07-17T03:12:23.924359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "2## NNsight\n",
    "# model_name = \"gpt2\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, force_download=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, force_download=True)\n",
    "model2 = LanguageModel('gpt2', device_map='auto')\n",
    "with model2.trace(prompt):\n",
    "    output = model2.lm_head.output.save()\n",
    "\n",
    "model1.tokenizer.decode(torch.argmax(output, dim=-1)[0])"
   ],
   "id": "cb484908fd9b2ac7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n-el Tower is a the middle centre Paris'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Section 1",
   "id": "f7a56557a51852e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T13:33:02.551497Z",
     "start_time": "2025-07-14T13:33:02.017721Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRecursionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache)\n\u001B[32m     15\u001B[39m tokenizer.pad_token = tokenizer.eos_token\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m gpt2_model = \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccess_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m gpt2_model.to(device).eval()\n\u001B[32m     20\u001B[39m tokenized = tokenizer(prompt, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m, padding=\u001B[38;5;28;01mTrue\u001B[39;00m, add_special_tokens=\u001B[38;5;28;01mFalse\u001B[39;00m)[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m].to(device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    569\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    570\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m571\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    572\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    573\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    574\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    575\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    576\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping.keys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    577\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/modeling_utils.py:279\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    277\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    281\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/modeling_utils.py:4342\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4336\u001B[39m     config = \u001B[38;5;28mcls\u001B[39m._autoset_attn_implementation(\n\u001B[32m   4337\u001B[39m         config, use_flash_attention_2=use_flash_attention_2, torch_dtype=torch_dtype, device_map=device_map\n\u001B[32m   4338\u001B[39m     )\n\u001B[32m   4340\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(model_init_context):\n\u001B[32m   4341\u001B[39m     \u001B[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4342\u001B[39m     model = \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4344\u001B[39m \u001B[38;5;66;03m# Make sure to tie the weights correctly\u001B[39;00m\n\u001B[32m   4345\u001B[39m model.tie_weights()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:983\u001B[39m, in \u001B[36mGPT2LMHeadModel.__init__\u001B[39m\u001B[34m(self, config)\u001B[39m\n\u001B[32m    981\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, config):\n\u001B[32m    982\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(config)\n\u001B[32m--> \u001B[39m\u001B[32m983\u001B[39m     \u001B[38;5;28mself\u001B[39m.transformer = \u001B[43mGPT2Model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    984\u001B[39m     \u001B[38;5;28mself\u001B[39m.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    986\u001B[39m     \u001B[38;5;66;03m# Model parallel\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:689\u001B[39m, in \u001B[36mGPT2Model.__init__\u001B[39m\u001B[34m(self, config)\u001B[39m\n\u001B[32m    685\u001B[39m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(config)\n\u001B[32m    687\u001B[39m \u001B[38;5;28mself\u001B[39m.embed_dim = config.hidden_size\n\u001B[32m--> \u001B[39m\u001B[32m689\u001B[39m \u001B[38;5;28mself\u001B[39m.wte = \u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEmbedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membed_dim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    690\u001B[39m \u001B[38;5;28mself\u001B[39m.wpe = nn.Embedding(config.max_position_embeddings, \u001B[38;5;28mself\u001B[39m.embed_dim)\n\u001B[32m    692\u001B[39m \u001B[38;5;28mself\u001B[39m.drop = nn.Dropout(config.embd_pdrop)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/torch/nn/modules/sparse.py:166\u001B[39m, in \u001B[36mEmbedding.__init__\u001B[39m\u001B[34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28mself\u001B[39m.scale_grad_by_freq = scale_grad_by_freq\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m     \u001B[38;5;28mself\u001B[39m.weight = \u001B[43mParameter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    167\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfactory_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    168\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequires_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_freeze\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    169\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    170\u001B[39m     \u001B[38;5;28mself\u001B[39m.reset_parameters()\n\u001B[32m    171\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/tracing/contexts/globals.py:30\u001B[39m, in \u001B[36mglobal_patch_class.<locals>.inner\u001B[39m\u001B[34m(cls, *args, **kwargs)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs):\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT:\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT.apply(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/tracing/contexts/globals.py:30\u001B[39m, in \u001B[36mglobal_patch_class.<locals>.inner\u001B[39m\u001B[34m(cls, *args, **kwargs)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs):\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT:\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT.apply(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs)\n",
      "    \u001B[31m[... skipping similar frames: global_patch_class.<locals>.inner at line 30 (1478 times)]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/tracing/contexts/globals.py:30\u001B[39m, in \u001B[36mglobal_patch_class.<locals>.inner\u001B[39m\u001B[34m(cls, *args, **kwargs)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs):\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT:\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT.apply(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/tracing/contexts/globals.py:29\u001B[39m, in \u001B[36mglobal_patch_class.<locals>.inner\u001B[39m\u001B[34m(cls, *args, **kwargs)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT:\n\u001B[32m     30\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(*args, **kwargs)\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m GlobalTracingContext.GLOBAL_TRACING_CONTEXT.apply(\u001B[38;5;28mcls\u001B[39m, *args, **kwargs)\n",
      "\u001B[31mRecursionError\u001B[39m: maximum recursion depth exceeded"
     ]
    }
   ],
   "execution_count": 33,
   "source": [
    "# Standard\n",
    "model_name = 'gpt2'\n",
    "batchsize = 4\n",
    "quantize = ''\n",
    "data = 'DC'\n",
    "trial = True\n",
    "method = 'logit-lens'\n",
    "cache = os.path.expanduser('./tmp/cashe/')\n",
    "\n",
    "# article2tokens = json.load(open(f\"data/{data}/tokens.json\"))\n",
    "# loss_fct = CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n",
    "\n",
    "access_token = HUFFINGFACE_KEY\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token, cache_dir=cache)\n",
    "gpt2_model.to(device).eval()\n",
    "\n",
    "tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True, add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "output = gpt2_model(tokenized, output_hidden_states=True)\n",
    "logit = gpt2_model.lm_head(torch.stack(output[2]).to(device))\n",
    "tokenizer.decode(torch.argmax(logit, dim=-1)[0][-1])"
   ],
   "id": "4f18f79b5cc7c422"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T13:51:18.381639Z",
     "start_time": "2025-07-14T13:51:17.666856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize the prompt\n",
    "model2 = LanguageModel('gpt2', device_map='auto')\n",
    "input_ids = model2.tokenizer(prompt, return_tensors='pt').input_ids.to(model2.device)\n",
    "\n",
    "# Store generated tokens\n",
    "generated = input_ids.clone()\n",
    "\n",
    "# Autoregressive generation loop\n",
    "for _ in range(10):\n",
    "    with model2.trace(generated) as trace:\n",
    "        output = trace.model.lm_head.output.save()\n",
    "\n",
    "    logits = output.value\n",
    "    next_token_logits = logits[:, -1, :]\n",
    "    next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
    "\n",
    "    generated = torch.cat((generated, next_token_id), dim=1)\n",
    "\n",
    "# Decode full output\n",
    "output_text = model2.tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ],
   "id": "6ba47a15f9e670c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Autoregressive generation loop\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m10\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mmodel2\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m     11\u001B[39m         output = trace.model.lm_head.output.save()\n\u001B[32m     13\u001B[39m     logits = output.value\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/modeling/mixins/remoteable.py:38\u001B[39m, in \u001B[36mRemoteableMixin.trace\u001B[39m\u001B[34m(self, method, backend, remote, blocking, trace, scan, *inputs, **kwargs)\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(backend, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m     35\u001B[39m     backend = RemoteBackend(\n\u001B[32m     36\u001B[39m         \u001B[38;5;28mself\u001B[39m.to_model_key(), host=backend, blocking=blocking\n\u001B[32m     37\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/intervention/base.py:193\u001B[39m, in \u001B[36mNNsight.trace\u001B[39m\u001B[34m(self, trace, scan, method, invoker_kwargs, backend, *inputs, **kwargs)\u001B[39m\n\u001B[32m    190\u001B[39m invoker_kwargs[\u001B[33m'\u001B[39m\u001B[33mscan\u001B[39m\u001B[33m'\u001B[39m] = scan\n\u001B[32m    192\u001B[39m \u001B[38;5;66;03m# Enter an invoker\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m193\u001B[39m \u001B[43mtracer\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minvoker_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__enter__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[38;5;66;03m# If trace is False, we'll enter the Tracer context immediately and enter an Invoker context with the provided inputs as well.\u001B[39;00m\n\u001B[32m    196\u001B[39m \u001B[38;5;66;03m# We'll also save the output of the model and return its value directly.\u001B[39;00m\n\u001B[32m    197\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m trace:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/intervention/contexts/invoker.py:79\u001B[39m, in \u001B[36mInvoker.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     76\u001B[39m util.apply(\u001B[38;5;28mself\u001B[39m.inputs, check_for_proxies, InterventionProxy)\n\u001B[32m     78\u001B[39m \u001B[38;5;66;03m# We dont want to create new proxies during scanning/prepare_inputs so we exit the global tracing context.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mGlobalTracingContext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexit_global_tracing_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     80\u001B[39m \n\u001B[32m     81\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If we dont have proxies we can immediately prepare the input so the user can see it and the batch_size.\u001B[39;49;00m\n\u001B[32m     82\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhas_proxies_in_inputs\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtracer\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_prepare_input\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     85\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/tracing/contexts/globals.py:106\u001B[39m, in \u001B[36mGlobalTracingContext.GlobalTracingExit.__exit__\u001B[39m\u001B[34m(self, exc_type, exc_val, traceback)\u001B[39m\n\u001B[32m    102\u001B[39m     GlobalTracingContext.PATCHER.\u001B[34m__enter__\u001B[39m()\n\u001B[32m    104\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc_val, \u001B[38;5;167;01mBaseException\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m106\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc_val\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/intervention/contexts/invoker.py:84\u001B[39m, in \u001B[36mInvoker.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m GlobalTracingContext.exit_global_tracing_context():\n\u001B[32m     80\u001B[39m \n\u001B[32m     81\u001B[39m     \u001B[38;5;66;03m# If we dont have proxies we can immediately prepare the input so the user can see it and the batch_size.\u001B[39;00m\n\u001B[32m     82\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_proxies_in_inputs:\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m         \u001B[38;5;28mself\u001B[39m.inputs, \u001B[38;5;28mself\u001B[39m.batch_size = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtracer\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_prepare_input\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     85\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     88\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.scan:\n\u001B[32m     90\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[38;5;28mself\u001B[39m.inputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/modeling/language.py:245\u001B[39m, in \u001B[36mLanguageModel._prepare_input\u001B[39m\u001B[34m(self, input_ids, labels, *inputs, **kwargs)\u001B[39m\n\u001B[32m    242\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    243\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m245\u001B[39m     inputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    247\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    248\u001B[39m         labels = \u001B[38;5;28mself\u001B[39m._tokenize(labels, **kwargs)[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/nnsight/modeling/language.py:203\u001B[39m, in \u001B[36mLanguageModel._tokenize\u001B[39m\u001B[34m(self, inputs, **kwargs)\u001B[39m\n\u001B[32m    201\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs[\u001B[32m0\u001B[39m], \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    202\u001B[39m     inputs = [{\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m: ids} \u001B[38;5;28;01mfor\u001B[39;00m ids \u001B[38;5;129;01min\u001B[39;00m inputs]\n\u001B[32m--> \u001B[39m\u001B[32m203\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.tokenizer(inputs, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m, padding=\u001B[38;5;28;01mTrue\u001B[39;00m, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3362\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.pad\u001B[39m\u001B[34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001B[39m\n\u001B[32m   3356\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   3357\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtype of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfirst_element\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m unknown: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(first_element)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3358\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mShould be one of a python, numpy, pytorch or tensorflow object.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3359\u001B[39m         )\n\u001B[32m   3361\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m encoded_inputs.items():\n\u001B[32m-> \u001B[39m\u001B[32m3362\u001B[39m         encoded_inputs[key] = \u001B[43mto_py_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3364\u001B[39m \u001B[38;5;66;03m# Convert padding_strategy in PaddingStrategy\u001B[39;00m\n\u001B[32m   3365\u001B[39m padding_strategy, _, max_length, _ = \u001B[38;5;28mself\u001B[39m._get_padding_truncation_strategies(\n\u001B[32m   3366\u001B[39m     padding=padding, max_length=max_length, verbose=verbose\n\u001B[32m   3367\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/utils/generic.py:276\u001B[39m, in \u001B[36mto_py_obj\u001B[39m\u001B[34m(obj)\u001B[39m\n\u001B[32m    274\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    275\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\u001B[43mto_py_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mo\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    278\u001B[39m framework_to_py_obj = {\n\u001B[32m    279\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.tolist(),\n\u001B[32m    280\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.numpy().tolist(),\n\u001B[32m    281\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mjax\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: np.asarray(obj).tolist(),\n\u001B[32m    282\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mnp\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.tolist(),\n\u001B[32m    283\u001B[39m }\n\u001B[32m    285\u001B[39m \u001B[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/utils/generic.py:276\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    274\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    275\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mto_py_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m obj]\n\u001B[32m    278\u001B[39m framework_to_py_obj = {\n\u001B[32m    279\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.tolist(),\n\u001B[32m    280\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.numpy().tolist(),\n\u001B[32m    281\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mjax\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: np.asarray(obj).tolist(),\n\u001B[32m    282\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mnp\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.tolist(),\n\u001B[32m    283\u001B[39m }\n\u001B[32m    285\u001B[39m \u001B[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/utils/generic.py:289\u001B[39m, in \u001B[36mto_py_obj\u001B[39m\u001B[34m(obj)\u001B[39m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m framework, test_func \u001B[38;5;129;01min\u001B[39;00m framework_to_test_func.items():\n\u001B[32m    288\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m test_func(obj):\n\u001B[32m--> \u001B[39m\u001B[32m289\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mframework_to_py_obj\u001B[49m\u001B[43m[\u001B[49m\u001B[43mframework\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[38;5;66;03m# tolist also works on 0d np arrays\u001B[39;00m\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, np.number):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/surprisal_internal_layers/lib/python3.11/site-packages/transformers/utils/generic.py:279\u001B[39m, in \u001B[36mto_py_obj.<locals>.<lambda>\u001B[39m\u001B[34m(obj)\u001B[39m\n\u001B[32m    275\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    276\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [to_py_obj(o) \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m obj]\n\u001B[32m    278\u001B[39m framework_to_py_obj = {\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    280\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.numpy().tolist(),\n\u001B[32m    281\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mjax\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: np.asarray(obj).tolist(),\n\u001B[32m    282\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mnp\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj.tolist(),\n\u001B[32m    283\u001B[39m }\n\u001B[32m    285\u001B[39m \u001B[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001B[39;00m\n\u001B[32m    286\u001B[39m framework_to_test_func = _get_frameworks_and_test_func(obj)\n",
      "\u001B[31mNotImplementedError\u001B[39m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-14T13:17:38.277601Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "11b949e614f0c681",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# it seems that all packages actually acess the same cache somewhere, force_downloading the model using transformers seem to improve all of them",
   "id": "265fd70954459096"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
