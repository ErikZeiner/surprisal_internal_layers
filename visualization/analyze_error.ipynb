{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "from patsy import dmatrices\n",
    "\n",
    "DATA = \"DC\"\n",
    "RECOMPUTE_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECOMPUTE_DATA:\n",
    "    df_original = pd.read_csv(f\"../data/{DATA}/all.txt.averaged_rt.annotation\")\n",
    "    df_original = df_original.sort_values([\"article\", \"sent_id\", \"tokenN_in_sent\"])\n",
    "    df = df_original.copy()\n",
    "    df = df[df[\"tokenN_in_sent\"] > 0]\n",
    "    df = df[df[\"is_first\"] == False]\n",
    "\n",
    "    # load results\n",
    "    target_files = glob.glob(f\"../results/tuned-lens/{DATA}/**/surprisal*.time\", recursive=True)\n",
    "    layer2score = {}\n",
    "    model2layer2score = defaultdict(dict)\n",
    "    for file in target_files:\n",
    "        layer = file.split(\".\")[-2]\n",
    "        model = file.split(\"/\")[-2]\n",
    "\n",
    "        if layer == \"layerAverage\":\n",
    "            continue\n",
    "        with open(file) as f:\n",
    "            layer_avg_loglik = f.readlines()[1].strip().split()[-1]\n",
    "            layer_avg_loglik = float(layer_avg_loglik)\n",
    "            layer2score[layer] = layer_avg_loglik\n",
    "            model2layer2score[model][layer] = layer_avg_loglik\n",
    "\n",
    "    # load surprisals\n",
    "\n",
    "    model2article2interest = defaultdict(dict)\n",
    "    model2last_layer = {}\n",
    "    model2best_layer = {}\n",
    "\n",
    "    target_files = glob.glob(f\"../results/tuned-lens/{DATA}/**/surprisal.json\", recursive=True)\n",
    "    for target_file in target_files:\n",
    "        article2interest = json.load(open(target_file))\n",
    "        model = target_file.split(\"/\")[-2]\n",
    "        model2article2interest[model] = article2interest\n",
    "        layer2score = model2layer2score[model]\n",
    "        print(model)\n",
    "        model2last_layer[model] = sorted(layer2score.items(), key=lambda x: int(x[0].replace(\"layer\", \"\").replace(\"Average\", \"-1\")))[-1][0].replace(\"layer\", \"\")\n",
    "        model2best_layer[model] = sorted(layer2score.items(), key=lambda x: x[1])[-1][0].replace(\"layer\", \"\")\n",
    "\n",
    "    # compute residual errors\n",
    "\n",
    "    def modeling(layer_id, article2interest):\n",
    "        # print(layer_id)\n",
    "        all_interests = [sup for _, sents_sups in sorted(article2interest[layer_id].items(), key=lambda x: int(x[0])) for sent_sups in sents_sups for sup in sent_sups]\n",
    "        mean_surprisal = mean(all_interests)\n",
    "        df = df_original.copy()\n",
    "\n",
    "        df[\"interest\"] = df_original.apply(lambda x: article2interest[layer_id][str(x[\"article\"])][x[\"sent_id\"]][x[\"tokenN_in_sent\"]], axis=1)\n",
    "        df[\"interest_prev_1\"] = [mean_surprisal] + list(df[\"interest\"])[:-1]\n",
    "        df[\"interest_prev_1\"] = df.apply(lambda x: x[\"interest_prev_1\"] if x[\"tokenN_in_sent\"] > 0 else mean_surprisal, axis=1)\n",
    "        df[\"interest_prev_2\"] = [mean_surprisal, mean_surprisal] + list(df[\"interest\"])[:-2]\n",
    "        df[\"interest_prev_2\"] = df.apply(lambda x: x[\"interest_prev_2\"] if x[\"tokenN_in_sent\"] > 1 else mean_surprisal, axis=1)\n",
    "\n",
    "\n",
    "        target_df = df.copy()\n",
    "        target = \"time\"\n",
    "        formula = f'{target} ~ interest + interest_prev_1 + interest_prev_2 + length + log_gmean_freq +  + length_prev_1 + log_gmean_freq_prev_1 + length_prev_2 + log_gmean_freq_prev_2'\n",
    "        baseline_formula = f'{target} ~ interest_prev_1 + interest_prev_2 + length + log_gmean_freq  + length_prev_1 + log_gmean_freq_prev_1 + length_prev_2 + log_gmean_freq_prev_2'\n",
    "\n",
    "        target_df = target_df[target_df[\"tokenN_in_sent\"] > 0]\n",
    "        target_df = target_df[target_df[\"is_first\"] == False]\n",
    "\n",
    "        y, X = dmatrices(formula, data=target_df, return_type='dataframe')\n",
    "        mod = sm.OLS(y, X)\n",
    "        res = mod.fit()\n",
    "\n",
    "        y_baseline, X_baseline = dmatrices(baseline_formula, data=target_df, return_type='dataframe')\n",
    "        mod_baseline = sm.OLS(y_baseline, X_baseline)\n",
    "        res_baseline = mod_baseline.fit() \n",
    "        return  abs(res_baseline.resid) - abs(res.resid), res_baseline.mse_model - res.mse_model # higher is better\n",
    "\n",
    "\n",
    "    model2layer2residuals = defaultdict(dict)\n",
    "    model2layer2mse = defaultdict(dict)\n",
    "\n",
    "    for model in model2last_layer.keys():\n",
    "        print(model)\n",
    "        last_layer = model2last_layer[model]\n",
    "        article2interest = model2article2interest[model]\n",
    "        last_residuals, mse = modeling(last_layer, article2interest)\n",
    "        layer2mse = {}\n",
    "        layer2residuals = {}\n",
    "        for layer_id in article2interest.keys():\n",
    "            residuals, mse = modeling(layer_id, article2interest)\n",
    "            model2layer2residuals[model][layer_id] =  residuals - last_residuals\n",
    "            model2layer2mse[model][layer_id] = mse\n",
    "\n",
    "    \n",
    "    dfs = []\n",
    "    for model, layer2residuals in model2layer2residuals.items():\n",
    "        df_regression = df.copy()\n",
    "        print(model)\n",
    "        best_residuals = layer2residuals[model2best_layer[model]]\n",
    "        df_regression[\"residuals_best\"] = best_residuals\n",
    "        df_regression[\"model\"] = model\n",
    "        dfs.append(df_regression)\n",
    "    df_regression = pd.concat(dfs)\n",
    "    df_regression.to_csv(f\"../results/{DATA}_error_analysis.csv\", index=False)\n",
    "else:\n",
    "    df_regression = pd.read_csv(f\"../results/{DATA}_error_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}                & residuals\\_best  & \\textbf{  R-squared:         } &      0.009    \\\\\n",
      "\\textbf{Model:}                        &       OLS        & \\textbf{  Adj. R-squared:    } &      0.009    \\\\\n",
      "\\textbf{Method:}                       &  Least Squares   & \\textbf{  F-statistic:       } &      113.5    \\\\\n",
      "\\textbf{Date:}                         & Tue, 07 Jan 2025 & \\textbf{  Prob (F-statistic):} &      0.00     \\\\\n",
      "\\textbf{Time:}                         &     15:10:10     & \\textbf{  Log-Likelihood:    } & -2.4625e+06   \\\\\n",
      "\\textbf{No. Observations:}             &      672896      & \\textbf{  AIC:               } &  4.925e+06    \\\\\n",
      "\\textbf{Df Residuals:}                 &      672839      & \\textbf{  BIC:               } &  4.926e+06    \\\\\n",
      "\\textbf{Df Model:}                     &          56      & \\textbf{                     } &               \\\\\n",
      "\\textbf{Covariance Type:}              &    nonrobust     & \\textbf{                     } &               \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}                     &       0.0801  &        0.430     &     0.186  &         0.852        &       -0.764    &        0.924     \\\\\n",
      "\\textbf{model[T.gpt2-large]}           &       0.1510  &        0.061     &     2.490  &         0.013        &        0.032    &        0.270     \\\\\n",
      "\\textbf{model[T.gpt2-xl]}              &       0.1647  &        0.061     &     2.716  &         0.007        &        0.046    &        0.284     \\\\\n",
      "\\textbf{model[T.opt-1.3b]}             &       0.1293  &        0.061     &     2.132  &         0.033        &        0.010    &        0.248     \\\\\n",
      "\\textbf{model[T.opt-125m]}             &       0.0182  &        0.061     &     0.301  &         0.764        &       -0.101    &        0.137     \\\\\n",
      "\\textbf{model[T.opt-6.7b]}             &       0.1898  &        0.061     &     3.131  &         0.002        &        0.071    &        0.309     \\\\\n",
      "\\textbf{model[T.pythia-1.4b-deduped]}  &       0.0754  &        0.061     &     1.243  &         0.214        &       -0.043    &        0.194     \\\\\n",
      "\\textbf{model[T.pythia-12b-deduped]}   &       0.1649  &        0.061     &     2.719  &         0.007        &        0.046    &        0.284     \\\\\n",
      "\\textbf{model[T.pythia-160m-deduped]}  &       0.1237  &        0.061     &     2.040  &         0.041        &        0.005    &        0.243     \\\\\n",
      "\\textbf{model[T.pythia-1b-deduped-v0]} &       0.0695  &        0.061     &     1.146  &         0.252        &       -0.049    &        0.188     \\\\\n",
      "\\textbf{model[T.pythia-2.8b-deduped]}  &       0.1212  &        0.061     &     1.998  &         0.046        &        0.002    &        0.240     \\\\\n",
      "\\textbf{model[T.pythia-410m-deduped]}  &       0.0607  &        0.061     &     1.001  &         0.317        &       -0.058    &        0.180     \\\\\n",
      "\\textbf{model[T.pythia-6.9b-deduped]}  &       0.1534  &        0.061     &     2.529  &         0.011        &        0.035    &        0.272     \\\\\n",
      "\\textbf{model[T.pythia-70m-deduped]}   &      -0.0478  &        0.061     &    -0.788  &         0.431        &       -0.167    &        0.071     \\\\\n",
      "\\textbf{pos[T.\\$]}                     &      -0.1911  &        0.776     &    -0.246  &         0.805        &       -1.711    &        1.329     \\\\\n",
      "\\textbf{pos[T.,]}                      &      -4.1266  &        0.985     &    -4.188  &         0.000        &       -6.058    &       -2.195     \\\\\n",
      "\\textbf{pos[T..]}                      &      -2.5070  &        1.327     &    -1.890  &         0.059        &       -5.107    &        0.093     \\\\\n",
      "\\textbf{pos[T.CC]}                     &      -0.7410  &        0.431     &    -1.719  &         0.086        &       -1.586    &        0.104     \\\\\n",
      "\\textbf{pos[T.CD]}                     &      -1.6381  &        0.443     &    -3.699  &         0.000        &       -2.506    &       -0.770     \\\\\n",
      "\\textbf{pos[T.DT]}                     &      -0.9570  &        0.428     &    -2.238  &         0.025        &       -1.795    &       -0.119     \\\\\n",
      "\\textbf{pos[T.EX]}                     &      -1.5530  &        0.489     &    -3.176  &         0.001        &       -2.511    &       -0.595     \\\\\n",
      "\\textbf{pos[T.FW]}                     &       4.2889  &        0.580     &     7.395  &         0.000        &        3.152    &        5.426     \\\\\n",
      "\\textbf{pos[T.IN]}                     &      -1.1206  &        0.427     &    -2.625  &         0.009        &       -1.957    &       -0.284     \\\\\n",
      "\\textbf{pos[T.JJ]}                     &      -1.4790  &        0.427     &    -3.461  &         0.001        &       -2.317    &       -0.641     \\\\\n",
      "\\textbf{pos[T.JJR]}                    &      -1.6572  &        0.463     &    -3.580  &         0.000        &       -2.565    &       -0.750     \\\\\n",
      "\\textbf{pos[T.JJS]}                    &      -2.1918  &        0.488     &    -4.489  &         0.000        &       -3.149    &       -1.235     \\\\\n",
      "\\textbf{pos[T.MD]}                     &      -1.6324  &        0.435     &    -3.749  &         0.000        &       -2.486    &       -0.779     \\\\\n",
      "\\textbf{pos[T.NN]}                     &      -2.0801  &        0.427     &    -4.876  &         0.000        &       -2.916    &       -1.244     \\\\\n",
      "\\textbf{pos[T.NNP]}                    &      -1.0809  &        0.428     &    -2.523  &         0.012        &       -1.921    &       -0.241     \\\\\n",
      "\\textbf{pos[T.NNPS]}                   &      -5.2269  &        0.484     &   -10.804  &         0.000        &       -6.175    &       -4.279     \\\\\n",
      "\\textbf{pos[T.NNS]}                    &      -2.1715  &        0.428     &    -5.071  &         0.000        &       -3.011    &       -1.332     \\\\\n",
      "\\textbf{pos[T.PDT]}                    &      -2.2381  &        0.535     &    -4.183  &         0.000        &       -3.287    &       -1.189     \\\\\n",
      "\\textbf{pos[T.POS]}                    &      -2.0896  &        0.449     &    -4.651  &         0.000        &       -2.970    &       -1.209     \\\\\n",
      "\\textbf{pos[T.PRP]}                    &      -1.0883  &        0.430     &    -2.529  &         0.011        &       -1.932    &       -0.245     \\\\\n",
      "\\textbf{pos[T.PRP\\$]}                  &      -1.4344  &        0.435     &    -3.296  &         0.001        &       -2.287    &       -0.581     \\\\\n",
      "\\textbf{pos[T.RB]}                     &      -1.7242  &        0.428     &    -4.026  &         0.000        &       -2.564    &       -0.885     \\\\\n",
      "\\textbf{pos[T.RBR]}                    &      -1.8143  &        0.482     &    -3.761  &         0.000        &       -2.760    &       -0.869     \\\\\n",
      "\\textbf{pos[T.RBS]}                    &      -3.0363  &        0.529     &    -5.743  &         0.000        &       -4.073    &       -2.000     \\\\\n",
      "\\textbf{pos[T.RP]}                     &      -1.4753  &        0.456     &    -3.235  &         0.001        &       -2.369    &       -0.582     \\\\\n",
      "\\textbf{pos[T.SYM]}                    &       2.6044  &        0.901     &     2.889  &         0.004        &        0.838    &        4.371     \\\\\n",
      "\\textbf{pos[T.TO]}                     &      -0.6908  &        0.431     &    -1.602  &         0.109        &       -1.536    &        0.155     \\\\\n",
      "\\textbf{pos[T.UH]}                     &      -7.8480  &        0.759     &   -10.338  &         0.000        &       -9.336    &       -6.360     \\\\\n",
      "\\textbf{pos[T.VB]}                     &      -1.2679  &        0.429     &    -2.955  &         0.003        &       -2.109    &       -0.427     \\\\\n",
      "\\textbf{pos[T.VBD]}                    &      -1.6735  &        0.431     &    -3.885  &         0.000        &       -2.518    &       -0.829     \\\\\n",
      "\\textbf{pos[T.VBG]}                    &      -2.0877  &        0.433     &    -4.818  &         0.000        &       -2.937    &       -1.238     \\\\\n",
      "\\textbf{pos[T.VBN]}                    &      -1.7750  &        0.431     &    -4.118  &         0.000        &       -2.620    &       -0.930     \\\\\n",
      "\\textbf{pos[T.VBP]}                    &      -1.1485  &        0.432     &    -2.659  &         0.008        &       -1.995    &       -0.302     \\\\\n",
      "\\textbf{pos[T.VBZ]}                    &      -1.2311  &        0.431     &    -2.860  &         0.004        &       -2.075    &       -0.387     \\\\\n",
      "\\textbf{pos[T.WDT]}                    &      -1.2174  &        0.449     &    -2.714  &         0.007        &       -2.097    &       -0.338     \\\\\n",
      "\\textbf{pos[T.WP]}                     &      -1.0289  &        0.455     &    -2.264  &         0.024        &       -1.920    &       -0.138     \\\\\n",
      "\\textbf{pos[T.WP\\$]}                   &       0.1774  &        0.869     &     0.204  &         0.838        &       -1.525    &        1.880     \\\\\n",
      "\\textbf{pos[T.WRB]}                    &      -0.8454  &        0.456     &    -1.853  &         0.064        &       -1.740    &        0.049     \\\\\n",
      "\\textbf{has\\_punct[T.True]}            &      -1.6396  &        0.038     &   -43.221  &         0.000        &       -1.714    &       -1.565     \\\\\n",
      "\\textbf{has\\_num[T.True]}              &       2.3217  &        0.171     &    13.602  &         0.000        &        1.987    &        2.656     \\\\\n",
      "\\textbf{log\\_gmean\\_freq}              &       0.0142  &        0.007     &     1.930  &         0.054        &       -0.000    &        0.029     \\\\\n",
      "\\textbf{length}                        &       0.3629  &        0.007     &    51.621  &         0.000        &        0.349    &        0.377     \\\\\n",
      "\\textbf{tokenN\\_in\\_sent}              &      -0.0042  &        0.001     &    -3.958  &         0.000        &       -0.006    &       -0.002     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 187414.166 & \\textbf{  Durbin-Watson:     } &      1.992    \\\\\n",
      "\\textbf{Prob(Omnibus):} &    0.000   & \\textbf{  Jarque-Bera (JB):  } & 10052050.292  \\\\\n",
      "\\textbf{Skew:}          &    0.531   & \\textbf{  Prob(JB):          } &       0.00    \\\\\n",
      "\\textbf{Kurtosis:}      &   21.905   & \\textbf{  Cond. No.          } &   4.55e+03    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
      " [2] The condition number is large, 4.55e+03. This might indicate that there are \\newline\n",
      " strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices(\"residuals_best ~ log_gmean_freq  + length + tokenN_in_sent + model + pos + has_punct + has_num\" , data=df_regression, return_type='dataframe')\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "print(res.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_gmean_freq</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_gmean_freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.743818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>-0.743818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                log_gmean_freq    length\n",
       "log_gmean_freq        1.000000 -0.743818\n",
       "length               -0.743818  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regression[[\"log_gmean_freq\", \"length\"]].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cog_layers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
